---
# Posts need to have the `post` layout
layout: post
comments: true

# The title of your post
title: CUTç°¡ä»‹ - Contrastive Learning for Unpaired Image-to-Image Translation


# (Optional) Write a short (~150 characters) description of each blog post.
# This description is used to preview the page on search engines, social media, etc.
description: >
  Taesung Park, Alexei A. Efros, Richard Zhang, Jun-Yan Zhu. [Contrastive Learning for Unpaired Image-to-Image Translation](https://arxiv.org/abs/2007.15651). In ECCV'20.
 
# (Optional) Link to an image that represents your blog post.
# The aspect ratio should be ~16:9.
<!-- image: /assets/img/default.jpg -->
<!-- hide_image: true -->

# You can hide the description and/or image from the output
# (only visible to search engines) by setting:
# hide_description: true
# hide_image: true

# (Optional) Each post can have zero or more categories, and zero or more tags.
# The difference is that categories will be part of the URL, while tags will not.
# E.g. the URL of this post is <site.baseurl>/hydejack/2017/11/23/example-content/
categories: [Deep Learning, Computer Vision]
tags: []
# If you want a category or tag to have its own page,
# check out `_featured_categories` and `_featured_tags` respectively.
---
ECCV 2020 paper

Paper link: https://arxiv.org/abs/2007.15651

Github(Pytorch): https://github.com/taesungp/contrastive-unpaired-translation

Video link: https://www.youtube.com/watch?v=jSGOzjmN8q0
> æœ‰æ™‚é–“çš„äººéå¸¸æ¨è–¦è§€çœ‹ï¼Œä¸‹æ–‡å¤§é‡ä½¿ç”¨å½±ç‰‡æ‰€ä½¿ç”¨ä¹‹æŠ•å½±ç‰‡ã€‚

# ç°¡ä»‹

æœ¬æ–‡å°æ–¼éç›£ç£å¼åœ–åƒè½‰æ›ä»»å‹™(Unsupervised image-to-image translation)æå‡ºæ–°çš„æ¡†æ¶ï¼Œ

è©²æ¡†æ¶æ“ºè„«ä»¥å¾€ Cycle-GAN éœ€è¦ 2 çµ„ GAN ä¸¦ä½¿ç”¨ Cycle-consistency loss çš„æ¶æ§‹ï¼Œ

æ”¹ç‚ºåˆ©ç”¨å°æ¯”å­¸ç¿’(Contrastive Learning)ä¾†é¼“å‹µè¼¸å‡ºçš„åœ–ç‰‡ç›¸ä¼¼è¼¸å…¥åœ–ç‰‡ï¼Œ

å› æ­¤è©²æ¨¡å‹åªéœ€è¦ä¸€çµ„ GAN å³å¯é€²è¡Œåœ–åƒè½‰æ›ï¼Œ

ä»¥ä¸‹åœ–ç‚ºä¾‹ï¼Œé€éå°æ¯”å­¸ç¿’è®“å³é‚Šæ–‘é¦¬çš„é ­éƒ¨å€å¡Šè¦ç›¸ä¼¼å·¦é‚Šé¦¬çš„é ­éƒ¨ï¼Œ

ä¸¦ä¸”åˆ©ç”¨æ–‘é¦¬çš„å…¶ä»–éƒ¨ä½æˆ–æ˜¯èƒŒæ™¯(e.g., è…³ã€è‰åœ°ç­‰)ä½œç‚ºè² æ¨£æœ¬(Negative)ï¼Œ

é€éé€™æ¦‚å¿µå°‡æ•´å¼µåœ–åˆ‡åˆ†ç‚ºåœ–åƒå€å¡Š(Patch)é€²è¡Œå°æ¯”å­¸ç¿’ã€‚

![](/assets/img/2020-10-17-CUT/constra_intro.png)

![](/assets/img/2020-10-17-CUT/fig3.png)

# æ¦‚å¿µ

ä»¥é¦¬è®Šæˆæ–‘é¦¬çš„åœ–åƒè½‰æ›ä»»å‹™ç‚ºä¾‹ï¼Œ

æ¨¡å‹æœƒå¸Œæœ›å°‡é¦¬çš„éƒ¨åˆ†å¯ä»¥è½‰æ›æˆæ–‘é¦¬ï¼Œ

æ­¤éƒ¨åˆ†æˆ‘å€‘ç¨±ä½œå¤–è§€(Apperance)ï¼Œ

è€ŒèƒŒæ™¯æˆ–æ˜¯å…¶ä»–éƒ¨åˆ†ä¿æŒä¸è®Šï¼Œæ­¤è™•ç¨±ä½œçµæ§‹(Content)ã€‚

ä»¥å¾€çš„åšæ³•æ˜¯é€é GAN çš„å°æŠ—å¼å­¸ç¿’ä¾†è®“å¤–è§€éƒ¨åˆ†å­¸ç¿’å¦‚ä½•è®Šæˆæ–‘é¦¬ï¼Œ

ä¸¦åˆ©ç”¨ Cycle-consistency loss ä¾†å­¸ç¿’å…©è€…çš„é—œè¯æ€§ï¼Œ

ç„¶è€Œé€™é …æ¢ä»¶æœ‰æ™‚å€™å…¶å¯¦æ˜¯å¤ªéåš´è‹›ï¼Œ

ä»¥ä¸‹åœ–æ–‘é¦¬è½‰æ›æˆé¦¬çš„ä»»å‹™ç‚ºä¾‹ï¼Œ

![](/assets/img/2020-10-17-CUT/diverse_horse.png)

å‡è¨­ä¸€é–‹å§‹æ˜¯æ£•é¦¬è½‰æ›æˆæ–‘é¦¬ï¼Œä¹‹å¾Œå†å¾æ–‘é¦¬è½‰æ›æˆç™½é¦¬ï¼Œ

ä½†åƒ…åƒ…æ˜¯é¡è‰²è®Šæ›å°±æœƒä½¿ Cycle-consistency loss èªç‚ºé€™è½‰æ›çš„ä¸å¥½ã€‚

ä¸‹åœ–ç‚º Cycle-consistency loss çš„ç¤ºæ„åœ–ã€‚

![](/assets/img/2020-10-17-CUT/cycle_loss.png)

å› æ­¤æœ¬è«–æ–‡æå‡ºä¸€ç¨®æ›¿ä»£æ–¹æ³•ï¼Œ

é€éå­¸ç¿’ Mutual information ä¾†å­¸ç¿’åœ–ç‰‡ä¸­çš„çµæ§‹ï¼Œ
> æ­¤æ¦‚å¿µæ˜¯ä¾†è‡ªè©²ç¯‡è«–æ–‡ INFONCE Loss - [Representation Learning with Contrastive Predictive Coding]
>
> åœ¨éç›£ç£å¼çš„å­¸ç¿’ä¸­ï¼Œå¸Œæœ›èƒ½è®“æ¨¡å‹å­¸æœƒé«˜éšçš„ç‰¹å¾µï¼Œ
>
> é€é Mutual Informationï¼ˆç›¸äº’è³‡è¨Š) çš„æ¦‚å¿µå»å­¸ç¿’ä¸€å€‹ Latent vector - cã€‚
>
> æœªä¾†å¯é€éè©² Latent vector åªè¦åœ¨çµåˆå¹¾å±¤ Linear classification å°±å¯ä»¥æœ‰ä¸éŒ¯çš„åˆ†é¡æ•ˆæœã€‚
>
> æ¦‚å¿µå¯ä»¥å»çœ‹æ­¤ç¯‡ [ç°¡ä»‹ Self-Supervised Learning çš„è¿‘æœŸç™¼å±• (2018â€“2020)]

æœ€çµ‚é”æˆä¸éœ€ Cycle-consistency loss å°±å¯ä»¥æœ‰ä¸éŒ¯çš„åœ–åƒè½‰æ›æ•ˆæœã€‚

# æ¨¡å‹æ¶æ§‹

![](/assets/img/2020-10-17-CUT/fig1.png)

## Step1. Adversarial learning

é¦–å…ˆå°‡ä¸€å¼µåœ–ç‰‡ç¶“é Generator ç”Ÿæˆå‡ºåœ–ç‰‡æ¥è‘—é€²è¡Œå°æŠ—å¼å­¸ç¿’ï¼Œ

è®“ Generator ç¶“ç”± Adversarial loss ä¾†å­¸ç¿’å¦‚ä½•è¼¸å‡ºä¸€å¼µåƒç›®æ¨™ç¨®é¡çš„åœ–ç‰‡ã€‚

![](/assets/img/2020-10-17-CUT/eq1.png)

æ¥è‘—æˆ‘å€‘è£œå……ä¸€äº›ç”Ÿæˆå™¨çš„ç´°ç¯€ï¼Œ

é›–ç„¶æ¶æ§‹åœ–ä¸Šé¢å¯« G(Generator)ï¼Œ 

ä½†å…¶å¯¦ G æ˜¯ç”± Encoder å’Œ Decoder çµ„æˆã€‚

![](/assets/img/2020-10-17-CUT/enc_dec.png)

## Step2. Contrastive learning

æ¥è‘—æœƒé€²è¡Œå°æ¯”è¨“ç·´(Contrastive learning)ï¼Œ

<!-- ä¸»è¦æƒ³æ³•æ˜¯åˆ©ç”¨ INFONCE Loss æœ€å¤§åŒ– Mutual Informationï¼ˆç›¸äº’è³‡è¨Š)ï¼Œ -->

ç°¡å–®ä¾†èªªæˆ‘å€‘è¦å¸Œæœ›æ¨¡å‹å¯ä»¥æœ‰æ•ˆçš„å­¸æœƒæŸå€‹ç‰¹å¾µæ™‚ï¼ˆç¨±åš Queryï¼‰ï¼Œ

æˆ‘å€‘æœƒåˆ©ç”¨æ­£æ¨£æœ¬(Positive)ä»¥åŠè² æ¨£æœ¬(Negative)ä¾†å­¸ç¿’ï¼Œ

è€Œåœ¨åœ–åƒè½‰æ›çš„ä»»å‹™ä¸­å¯ä»¥é€éæå–ç›¸åŒåœ–åƒä½ç½®çš„å€å¡Šä½œç‚ºæ­£æ¨£æœ¬ï¼Œ

è€Œå…¶ä»–éƒ¨åˆ†å°±æ˜¯è² æ¨£æœ¬ã€‚

å°‡è¼¸å…¥åœ–åƒä»¥åŠè½‰æ›å¾Œçš„åœ–åƒç›¸åŒå€å¡Š(ä¸‹åœ–ç‚ºé¦¬çš„é ­)çš„éƒ¨åˆ†æˆ‘å€‘å¸Œæœ›è¶Šåƒè¶Šå¥½ï¼Œ

è€Œé¦¬çš„é ­èˆ‡å…¶ä»–éƒ¨åˆ†(é¦¬çš„èƒŒã€é¦¬çš„è…³ã€èƒŒæ™¯)èˆ‡é¦¬çš„é ­ä¸ç›¸é—œçš„éƒ¨åˆ†è¶Šä¸åƒè¶Šå¥½ï¼Œ

å› æ­¤åœ¨åšçš„äº‹æƒ…ç­‰åŒæ–¼åˆ©ç”¨ Cross-entropy åœ¨è¨“ç·´åˆ†é¡å™¨ã€‚

![](/assets/img/2020-10-17-CUT/patch_based.png)

å¯«æˆæ•¸å­¸å¼å°±æœƒè®Šæˆé€™æ¨£ï¼Œ v+(Postive)ã€v-(Negative)

![](/assets/img/2020-10-17-CUT/eq2.png)

å€¼å¾—ä¸€æçš„æ˜¯ä»¥å¾€æ˜¯é€éæ•´å¼µåœ–ç‰‡ä¾†é€²è¡Œå°æ¯”å­¸ç¿’ï¼Œ
> MoCo: He et al., CVPR20; SimCLR: Chen et al., ICML20

è€Œæœ¬è«–æ–‡æ˜¯åŸºæ–¼åœ–åƒå€å¡Š(Patch)ä¾†å¯¦ä½œçš„ã€‚

è£œå……æ¶æ§‹çš„ç´°ç¯€ï¼šæ•´é«”æ¶æ§‹æ˜¯ Generator(Encoder + Decoder) + Discriminator + MLP Network(H)

ä»¥å¾€ GAN æ¶æ§‹åªè¦ Generator + Discriminatorï¼Œ

è€Œæœ¬æ–‡å¢åŠ å°æ¯”è¨“ç·´ï¼Œ

å› æ­¤é‚„æœƒé€é Generator ä¸­çš„ Encoder èˆ‡ MLP é€²è¡Œå°æ¯”å­¸ç¿’ã€‚

## Multilayer, patchwise constractive learningï¼Œ

![](/assets/img/2020-10-17-CUT/Multi-patchwise.png)

ç°¡å–®ä¾†èªªæ˜¯ä¾æ“šä¸åŒå¤§å°çš„åœ–åƒå€å¡Šé€²è¡Œå­¸ç¿’ï¼Œ

Encoder ä¸­ä¸åŒçš„ Layer æ‰€è¼¸å‡ºçš„ç‰¹å¾µå¤§å°ä¸åŒï¼Œ

è€Œåˆ©ç”¨ä¸åŒå°ºåº¦çš„ç‰¹å¾µé€²è¡Œå°æ¯”å­¸ç¿’å¯ä»¥è®“æ¨¡å‹å­¸å¾—æ›´å¥½ã€‚

è€Œæ¥è‘—ä¹Ÿå°è³‡æ–™é›†å…§(External)çš„æ‰€æœ‰åœ–ç‰‡é€²è¡Œå°æ¯”å­¸ç¿’ï¼Œ

ç„¶è€Œæˆæ•ˆå»æ²’æœ‰ Patch çš„æ–¹å¼å¥½ã€‚

![](/assets/img/2020-10-17-CUT/inter_vs_external.png)

è€Œä½œè€…ä¹Ÿæå‡ºäº†è©²åŸå› å¯èƒ½æ˜¯å› ç‚ºåˆ©ç”¨å…¶ä»–åœ–ç‰‡çš„ Patch æœƒä¸å°å¿ƒå–æ¨£åˆ° Positive çš„éƒ¨åˆ†å»ä½œç‚º Negative åšå­¸ç¿’ï¼Œ

![](/assets/img/2020-10-17-CUT/External_failed.png)

å¦‚ä¸Šåœ–ï¼Œç•¶æˆ‘å€‘ç›®å‰æ‰€ Query çš„æ˜¯é¦¬çš„é ­éƒ¨ï¼Œ

ä½†ç•¶å–æ¨£æ•´å€‹è³‡æ–™é›†æ™‚ï¼Œ

æˆ‘å€‘ä¸çŸ¥é“è©²åœ–ç‰‡å“ªå€‹éƒ¨åˆ†æ˜¯é¦¬çš„é ­éƒ¨ï¼Œ

æ‰€ä»¥å¯èƒ½æœƒå–éŒ¯åœ–ç‰‡å€å¡Šï¼Œé€ æˆ False negativeã€‚

æœ€çµ‚çš„è¨“ç·´å…¬å¼å¦‚ä¸‹ï¼š

![](/assets/img/2020-10-17-CUT/eq5.png)

ä¸Šæ–¹çš„ ğœ†y æŒ‡çš„æ˜¯ Identity lossã€‚

![](/assets/img/2020-10-17-CUT/Identity_loss.png)



# æˆæœ

è€Œæœ¬æ–‡æå‡ºå…©ç¨®è¨­å®š
- CUT(æ¡ç”¨ Identity loss): ğœ†x = 1, ğœ†y = 1
- FastCUT(ä¸æ¡ç”¨ Identity loss): ğœ†x = 10, ğœ†y = 0

![](/assets/img/2020-10-17-CUT/fig3.png)

![](/assets/img/2020-10-17-CUT/table1.png)

Last layer only æŒ‡çš„æ˜¯æ²’æœ‰ä½¿ç”¨ Multilayer çš„æ–¹å¼åšå°æ¯”å­¸ç¿’ã€‚

![](/assets/img/2020-10-17-CUT/fig5.png)

é€éè¦–è¦ºåŒ–è§£é‡‹ Encoder æœ‰è¾¦æ³•å‘ˆç¾æ•´å¼µåœ–èˆ‡è©²é»ç›¸é—œæ€§ã€‚

![](/assets/img/2020-10-17-CUT/fig7.png)

é€éå°‡é«˜è§£æåº¦çš„å½±åƒæ‹†è§£æˆå°å€å¡Š(128 x 128)è¨“ç·´ï¼Œ

æ­¤è™•æœ‰ä¸€äº›ç´°ç¯€å¦‚é€é€² Discriminator æœƒå†åˆ‡åˆ†æˆ 64 x 64 çš„åœ–åƒå¤§å°ç­‰ç­‰çš„ï¼Œç¨±ä¹‹ç‚º SinCUTï¼Œ

æœ‰èˆˆè¶£çš„å»çœ‹å¯¦é©—éƒ¨åˆ†ï¼Œä¸‹æ–¹ç‚ºé«˜è§£æåº¦ç•«é¢¨è½‰æ›ã€‚

![](/assets/img/2020-10-17-CUT/fig9.png)

åœ¨ GTA5 ä»¥åŠ Cityscapes çš„ç•«é¢¨è½‰æ›ã€‚

![](/assets/img/2020-10-17-CUT/fig12.png)


# åƒè€ƒè³‡æ–™ï¼š

[Contrastive Learning for Unpaired Image-to-Image Translation]

[Youtube CUT: Contrastive Learning for Unpaired Image-to-Image Translation]

[Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks]

[ç°¡ä»‹ Self-Supervised Learning çš„è¿‘æœŸç™¼å±• (2018â€“2020)]

[ç°¡ä»‹ Self-Supervised Learning çš„è¿‘æœŸç™¼å±• (2018â€“2020)]:https://medium.com/@kelispinor/%E7%B0%A1%E4%BB%8B-self-supervised-learning-%E7%9A%84%E8%BF%91%E6%9C%9F%E7%99%BC%E5%B1%95-2018-2020-a3872662727d

[Representation Learning with Contrastive Predictive Coding]:https://arxiv.org/abs/1807.03748

[Contrastive Learning for Unpaired Image-to-Image Translation]:https://arxiv.org/abs/2007.15651

[Youtube CUT: Contrastive Learning for Unpaired Image-to-Image Translation]:https://www.youtube.com/watch?v=jSGOzjmN8q0

[Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks]:https://arxiv.org/pdf/1703.10593.pdf


